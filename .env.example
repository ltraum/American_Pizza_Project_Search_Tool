# =============================================================================
# Pizza Interview Search â€“ Environment Variables
# Copy to .env and set values. All are optional; config.py has defaults.
# =============================================================================

# -----------------------------------------------------------------------------
# Semantic Search Model
# -----------------------------------------------------------------------------
# Options: "all-MiniLM-L6-v2" (small, fast), "all-mpnet-base-v2" (better quality)
# For E5/BGE models (e.g. intfloat/e5-small-v2), also set USE_QUERY_PASSAGE_PREFIX=true
# and rebuild the index.
SEMANTIC_MODEL_NAME=all-MiniLM-L6-v2

# -----------------------------------------------------------------------------
# Search Limits
# -----------------------------------------------------------------------------
MAX_RESULTS=50
SEMANTIC_SEARCH_TOP_K=10
FULLTEXT_SEARCH_TOP_K=10

# -----------------------------------------------------------------------------
# Runtime
# -----------------------------------------------------------------------------
# Set to true to force CPU (e.g. on Windows without GPU).
WINDOWS_USE_CPU=true

# -----------------------------------------------------------------------------
# Query Expansion (AI-based, uses OpenAI)
# -----------------------------------------------------------------------------
# Set OPENAI_API_KEY=sk-... for AI expansion. If unset, falls back to rule-based.
ENABLE_QUERY_EXPANSION=true
QUERY_EXPANSION_MAX_TERMS=10
QUERY_EXPANSION_MODEL=gpt-3.5-turbo

# -----------------------------------------------------------------------------
# Multi-Query + RRF (when expansion is on)
# -----------------------------------------------------------------------------
# Embed original + expansion phrases separately and fuse with Reciprocal Rank Fusion.
# Recommended: leave true for better recall.
MULTI_QUERY_RRF=true
MULTI_QUERY_RRF_K=60
MULTI_QUERY_MAX_PHRASES=5

# -----------------------------------------------------------------------------
# Chunking for Semantic Index
# -----------------------------------------------------------------------------
# Smaller windows (window_size=1) improve recall for short queries like "family" or "spicy".
# Use CHUNK_WINDOW_SIZE=2 and CHUNK_OVERLAP=1 for two-sentence overlapping chunks.
CHUNK_WINDOW_SIZE=1
CHUNK_OVERLAP=0

# -----------------------------------------------------------------------------
# E5/BGE-Style Prefixes (only for models that need them)
# -----------------------------------------------------------------------------
# Set to true only when using intfloat/e5-* or BAAI/bge-* and rebuild the index.
# Leave false for all-MiniLM-L6-v2 and all-mpnet-base-v2.
USE_QUERY_PASSAGE_PREFIX=false
# QUERY_PREFIX=query:
# PASSAGE_PREFIX=passage:

# -----------------------------------------------------------------------------
# Optional: OpenAI for query expansion (put real key in .env, not here)
# ----------------------------------------------------------------------------
OPENAI_API_KEY=

# -----------------------------------------------------------------------------
# Optional: Simple password gate for shared-link deployments
# -----------------------------------------------------------------------------
# If both are set (non-empty), the web UI and APIs will require HTTP Basic auth.
UI_AUTH_USERNAME=
UI_AUTH_PASSWORD=

